{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load USPS on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import pickle\n",
    "import gzip\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = 'USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)\n",
    "USPS_Mat = np.array(USPSMat)\n",
    "USPS_Tar = np.array(USPSTar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "USPS_Target = np.array(USPSTar)\n",
    "USPS_Tar = keras.utils.to_categorical(USPSTar, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MNIST - confusion matrix using RFC :\n",
      "[[ 970    0    4    0    1    5    9    2    6    3]\n",
      " [   0 1122    1    0    0    1    3    5    1    5]\n",
      " [   1    2  997   11    2    1    1   22    4    1]\n",
      " [   0    4    7  966    0   14    0    2   11    9]\n",
      " [   0    2    4    0  947    2    2    1    3   15]\n",
      " [   1    2    1    7    0  851    4    0    7    5]\n",
      " [   3    2    1    0    5    7  936    1    4    1]\n",
      " [   1    0    9   12    0    2    0  981    4    4]\n",
      " [   3    1    7   12    2    4    3    3  925    9]\n",
      " [   0    0    1    2   25    5    0   11    9  957]]\n",
      " \n",
      " USPS - confusion matrix using RFC :\n",
      "[[  46    0   14   21    0   13   48    0   18    2]\n",
      " [ 157  506  417  109  210  302  286  546  286  332]\n",
      " [   9    2   68   25   18    7   63    7   25   15]\n",
      " [   0    0    1    8    0    1    0    0    2    0]\n",
      " [  91   43   53  133  148   42   58   44  164   66]\n",
      " [ 401  102  240  446  220  507  354  317  676  305]\n",
      " [   0    0    2    0    0    0    4    0    0    0]\n",
      " [1296 1347 1204 1258 1404 1128 1187 1086  828 1280]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    1    0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "n_train = 60000\n",
    "n_test = 10000\n",
    "indices = range(len(mnist.data))\n",
    "train_idx = range(0,n_train)\n",
    "test_idx = range(n_train+1,n_train+n_test)\n",
    "X_train, y_train = mnist.data[train_idx], mnist.target[train_idx]\n",
    "X_test, y_test = mnist.data[test_idx], mnist.target[test_idx]\n",
    "\n",
    "# SVM\n",
    "classifier1 = SVC(kernel='rbf', C=2, gamma = 0.05);\n",
    "classifier1.fit(X_train, y_train)\n",
    "y_pred_SVC1 = classifier2.predict(X_test)\n",
    "\n",
    " # SVM\n",
    "classifier1 = SVC(kernel='linear', C=2, gamma = 0.05);\n",
    "classifier1.fit(X_train, y_train)\n",
    "y_pred_SVC21 = classifier2.predict(X_test)\n",
    "y_pred_SVC22 = classifier2.predict(X_test)\n",
    "\n",
    "out_mnist = confusion_matrix(y_pred_svc, y_test)\n",
    "print(\" MNIST - confusion matrix using SVC :\")\n",
    "print(out_mnist)\n",
    "\n",
    "out_usps = confusion_matrix(y_pred_svc2, USPS_Target)\n",
    "print(\" USPS - confusion matrix using SVC :\")\n",
    "print(out_usps)\n",
    "\n",
    "#RandomForestClassifier\n",
    "classifier2 = RandomForestClassifier(n_estimators = 30);\n",
    "classifier2.fit(X_train, y_train)\n",
    "y_pred_RFC = classifier2.predict(X_test)\n",
    "y_pred_RFC2 = classifier2.predict(USPS_Mat)\n",
    "\n",
    "acc_mnist = accuracy_score(y_pred_RFC, y_test)\n",
    "out_mnist = confusion_matrix(y_pred_RFC, y_test)\n",
    "print(\" MNIST - confusion matrix using RFC :\")\n",
    "print(out_mnist)\n",
    "print(\" \")\n",
    "acc_usps = accuracy_score(y_pred_RFC2, USPS_Target)\n",
    "out_usps = confusion_matrix(y_pred_RFC2, USPS_Target)\n",
    "print(\" USPS - confusion matrix using RFC :\")\n",
    "print(out_usps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using MNIST is :  0.11865593279663983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9652965296529653"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_usps = accuracy_score(y_pred_RFC2, USPS_Target)\n",
    "print(\"Accuracy using MNIST is : \",+acc_usps)\n",
    "acc_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotIt(Y):\n",
    "    m = Y.shape[0]\n",
    "    targets = np.array(Y)\n",
    "    OHX = scipy.sparse.csr_matrix((np.ones(m), (Y, np.array(range(m)))))\n",
    "    OHX = np.array(OHX.todense()).T\n",
    "    n_lables = 10\n",
    "    targets = np.array(Y)\n",
    "    for i in range(50000):\n",
    "        ohm = np.zeros((targets.shape[0],n_lables))\n",
    "        ohm[np.arange(targets.shape[0]),targets]=1\n",
    "    return OHX\n",
    "def logistic_regression(x_train, real_target,ini_weit):\n",
    "    a = np.zeros((10))\n",
    "    for row in range(x_train.shape[0]):\n",
    "        current_row = x_train[row]\n",
    "        current_target = real_target[row]\n",
    "        local_sum = 0\n",
    "        Bias = 0\n",
    "        for i in range(10):\n",
    "            a[i] = np.dot(ini_weit[i],current_row) + Bias\n",
    "            local_sum = local_sum + np.exp(a[i])\n",
    "        y = np.zeros((10))\n",
    "        for j in range(10):\n",
    "            y[i] = (np.exp(a[j])) / (local_sum)\n",
    "        lr = 0.01\n",
    "        for k in range(10):\n",
    "            diff_weit = (y[k] - current_target[k])*current_row\n",
    "            ini_weit[k] = ini_weit[k] - (lr*diff_weit)\n",
    "    return ini_weit\n",
    "\n",
    "def pred(ini_weit, x_test):\n",
    "    a = np.zeros((10))\n",
    "    y_pred =  np.zeros(x_test.shape[0])\n",
    "    for row in range(x_test.shape[0]):\n",
    "        current_row = x_test[row]\n",
    "        local_sum = 0\n",
    "        Bias = 0\n",
    "        for i in range(10):\n",
    "            a[i] = np.dot(ini_weit[i],current_row) + Bias\n",
    "            local_sum = local_sum + np.exp(a[i])\n",
    "        y = np.zeros((10))\n",
    "        \n",
    "        for j in range(10):\n",
    "            y[i] = (np.exp(a[j])) / (local_sum)\n",
    "        y_pred[row] = np.argmax(y) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MNIST - confusion matrix using Logistic Regression :\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 980 1135 1032 1010  982  892  958 1028  974 1009]]\n",
      "Accuracy using MNIST is :  0.1009\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from math import exp\n",
    "filename = 'mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "x_train = training_data[0]\n",
    "x_target = training_data[1]\n",
    "x_test = test_data[0]\n",
    "test_target = test_data[1]\n",
    "real_target = oneHotIt(x_target)\n",
    "ini_weit = np.zeros([10,784],)\n",
    "calc_weit = logistic_regression(x_train, real_target,ini_weit)\n",
    "y_pred_logistic = pred(calc_weit, x_test)\n",
    "#y_pred_logistic2 = pred(calc_weit, USPS_Mat)\n",
    "\n",
    "\n",
    "\n",
    "out_mnist = confusion_matrix(y_pred_logistic, test_target)\n",
    "print(\" MNIST - confusion matrix using Logistic Regression :\")\n",
    "print(out_mnist)\n",
    "\n",
    "\n",
    "\n",
    "#out_usps = confusion_matrix(y_pred_logistic2, USPS_Target)\n",
    "#print(\" USPS - confusion matrix using Logistic Regression :\")\n",
    "#print(out_usps)\n",
    "\n",
    "#acc_usps = accuracy_score(y_pred_logistic2, USPS_Target)\n",
    "#print(\"Accuracy using USPS is : \",+acc_usps)\n",
    "\n",
    "acc_mnist = accuracy_score(y_pred_logistic, test_target)\n",
    "print(\"Accuracy using MNIST is : \",+acc_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " USPS - confusion matrix using Logistic Regression :\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [2000 2000 1999 2000 2000 2000 2000 2000 2000 2000]]\n",
      "Accuracy using USPS is :  0.10000500025001251\n"
     ]
    }
   ],
   "source": [
    "y_pred_logistic2 = pred(calc_weit, USPS_Mat)\n",
    "out_usps = confusion_matrix(y_pred_logistic2, USPS_Target)\n",
    "print(\" USPS - confusion matrix using Logistic Regression :\")\n",
    "print(out_usps)\n",
    "\n",
    "acc_usps = accuracy_score(y_pred_logistic2, USPS_Target)\n",
    "print(\"Accuracy using USPS is : \",+acc_usps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import pickle\n",
    "import gzip\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from math import exp\n",
    "filename = 'mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "x_train = training_data[0]\n",
    "x_target = training_data[1]\n",
    "x_test = test_data[0]\n",
    "test_target = test_data[1]\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "num_classes=10\n",
    "image_vector_size=28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], image_vector_size)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_vector_size)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "image_size = 784 \n",
    "model = Sequential()\n",
    "model.add(Dense(units=32, activation='sigmoid', input_shape=(image_size,)))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=10,verbose=False,validation_split=.1)\n",
    "\n",
    "\n",
    "loss,accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "y_pred_dense =  np.zeros(x_test.shape[0])\n",
    "y_pred_inter = model.predict(x_test)\n",
    "for i in range(y_pred_dense.shape[0]):\n",
    "    y_pred_dense[i] = np.argmax(y_pred_inter[i])\n",
    "    \n",
    "loss2,accuracy2 = model.evaluate(USPS_Mat, USPS_Tar, verbose=False)\n",
    "y_pred_dense2 =  np.zeros(USPS_Mat.shape[0])\n",
    "y_pred_inter2 = model.predict(USPS_Mat)\n",
    "for i in range(y_pred_dense2.shape[0]):\n",
    "    y_pred_dense2[i] = np.argmax(y_pred_inter2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " USPS - confusion matrix using DNN :\n",
      "[[ 289   17   21   12    4   27   52    3   32    4]\n",
      " [   0  177   12    2   22   13    1   72   15   61]\n",
      " [ 408  457 1483  200  103  389  829  486  364  198]\n",
      " [  72  583  238 1525  106  406  188  733  477  607]\n",
      " [  65   51   19    5  500   17   40    6   52   59]\n",
      " [ 103   50   75  130   57  828  178   13  374   32]\n",
      " [  81   29   33   13   27   89  589   20  106   12]\n",
      " [  32   41   26   31   62   62   12  199   20  297]\n",
      " [   8   16   15    7   33   20    2   28  119  114]\n",
      " [ 942  579   77   75 1086  149  109  440  441  616]]\n",
      " \n",
      "0.31626581329066455\n"
     ]
    }
   ],
   "source": [
    "out_usps = confusion_matrix(y_pred_dense2, USPS_Target)\n",
    "acc_usps = accuracy_score(y_pred_dense2, USPS_Target)\n",
    "print(\" USPS - confusion matrix using DNN :\")\n",
    "print(out_usps)\n",
    "print(\" \")\n",
    "print(acc_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST - confusion matrix using DNN :\n",
      "[[ 959    0   17    4    2   13   16    4    9    8]\n",
      " [   0 1111    3    5    0    5    3   11   10    5]\n",
      " [   3    1  916   29    3    5    5   26    7    4]\n",
      " [   0    3   11  859    1   39    0    3   17    4]\n",
      " [   0    1   11    1  908   14   11   10   14   65]\n",
      " [   5    0    0   48    0  724    9    0   28   11]\n",
      " [   7    4   22    5   15   28  911    1   15    1]\n",
      " [   2    2   14   19    1   14    0  913   16   18]\n",
      " [   4   13   34   31    7   36    3    4  848   10]\n",
      " [   0    0    4    9   45   14    0   56   10  883]]\n",
      " \n",
      "0.9032\n"
     ]
    }
   ],
   "source": [
    "test_target = test_data[1]\n",
    "out_mnist = confusion_matrix(y_pred_dense, test_target)\n",
    "acc_mnist = accuracy_score(y_pred_dense, test_target)\n",
    "print(\"MNIST - confusion matrix using DNN :\")\n",
    "print(out_mnist)\n",
    "print(\" \")\n",
    "print(acc_mnist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " USPS - confusion matrix using CNN :\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [2000 2000 1999 2000 2000 2000 2000 2000 2000 2000]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "MNIST - confusion matrix using CNN :\n",
      "[[ 972    0    5    0    1    1    7    1    3    4]\n",
      " [   0 1130    0    0    0    0    4    5    0    4]\n",
      " [   2    3 1012    1    1    0    1   12    1    1]\n",
      " [   0    1    8  995    0    1    0    5   10    5]\n",
      " [   0    0    0    0  947    0    2    0    1    5]\n",
      " [   3    0    0   12    0  889   16    1   19   17]\n",
      " [   1    1    0    0    4    1  926    0    0    0]\n",
      " [   1    0    1    1    0    0    0  986    2    6]\n",
      " [   1    0    6    1    3    0    2    2  932    3]\n",
      " [   0    0    0    0   26    0    0   16    6  964]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import pickle\n",
    "import gzip\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "from math import exp\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "filename = 'mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "x_train = training_data[0]\n",
    "x_target = training_data[1]\n",
    "x_test = test_data[0]\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "num_classes=10\n",
    "image_vector_size=28*28\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28,1)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "image_size = 784\n",
    "chanDim = 1\n",
    "model = Sequential()\n",
    "# CONV => RELU => POOL layer set\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(28,28,1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# (CONV => RELU) * 2 => POOL layer set\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# (CONV => RELU) * 3 => POOL layer set\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "        \n",
    "\n",
    "# first (and only) set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "# softmax classifier\n",
    "model.add(Dense(units=num_classes, activation='softmax'))\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=2,verbose=False,validation_split=.1)\n",
    "\n",
    "\n",
    "loss,accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "y_pred_con =  np.zeros(x_test.shape[0])\n",
    "y_pred_inter = model.predict(x_test)\n",
    "for i in range(y_pred_con.shape[0]):\n",
    "    y_pred_con[i] = np.argmax(y_pred_inter[i])\n",
    "    \n",
    "    \n",
    "USPS_Mat = USPS_Mat.reshape(USPS_Mat.shape[0], 28,28,1)\n",
    "loss2,accuracy2 = model.evaluate(USPS_Mat, USPS_Tar, verbose=False)\n",
    "y_pred_con2 =  np.zeros(USPS_Mat.shape[0])\n",
    "y_pred_inter2 = model.predict(USPS_Mat)\n",
    "for i in range(y_pred_con2.shape[0]):\n",
    "    y_pred_con2[i] = np.argmax(y_pred_inter2[i])\n",
    "    \n",
    "    \n",
    "out_usps = confusion_matrix(y_pred_con2, USPS_Target)\n",
    "print(\" USPS - confusion matrix using CNN :\")\n",
    "print(out_usps)\n",
    "\n",
    "\n",
    "test_target = test_data[1]\n",
    "out_mnist = confusion_matrix(y_pred_con, test_target)\n",
    "print(\"MNIST - confusion matrix using CNN :\")\n",
    "print(out_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST - confusion matrix using CNN :\n",
      "[[ 973    0    3    0    1    1    7    1    3    4]\n",
      " [   0 1130    0    0    1    0    5    5    0    4]\n",
      " [   1    4 1019    2    1    0    4   15    4    0]\n",
      " [   0    1    3  991    0    4    0    4    2    6]\n",
      " [   0    0    0    0  950    0    3    0    2    5]\n",
      " [   1    0    0   11    0  885    5    1    7    7]\n",
      " [   1    0    0    0    5    1  930    0    1    0]\n",
      " [   1    0    3    2    1    1    0  988    2    6]\n",
      " [   3    0    4    4    4    0    4    2  948    3]\n",
      " [   0    0    0    0   19    0    0   12    5  974]]\n",
      " \n",
      "0.9788\n"
     ]
    }
   ],
   "source": [
    "test_target = test_data[1]\n",
    "out_mnist = confusion_matrix(y_pred_con, test_target)\n",
    "print(\"MNIST - confusion matrix using CNN :\")\n",
    "print(out_mnist)\n",
    "acc_mnist = accuracy_score(y_pred_con, test_target)\n",
    "print(\" \")\n",
    "print(acc_mnist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " USPS - confusion matrix using CNN :\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [2000 2000 1999 2000 2000 2000 2000 2000 2000 2000]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      " \n",
      "0.10000500025001251\n"
     ]
    }
   ],
   "source": [
    "USPS_Mat = USPS_Mat.reshape(USPS_Mat.shape[0], 28,28,1)\n",
    "loss2,accuracy2 = model.evaluate(USPS_Mat, USPS_Tar, verbose=False)\n",
    "y_pred_con2 =  np.zeros(USPS_Mat.shape[0])\n",
    "y_pred_inter2 = model.predict(USPS_Mat)\n",
    "for i in range(y_pred_con2.shape[0]):\n",
    "    y_pred_con2[i] = np.argmax(y_pred_inter2[i])\n",
    "    \n",
    "    \n",
    "out_usps = confusion_matrix(y_pred_con2, USPS_Target)\n",
    "print(\" USPS - confusion matrix using CNN :\")\n",
    "print(out_usps)\n",
    "acc_mnist = accuracy_score(y_pred_con2, USPS_Target)\n",
    "print(\" \")\n",
    "print(acc_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19999"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USPS_Mat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maj_vote(a,b,d):\n",
    "    local = []\n",
    "    new_list = []\n",
    "    maj_rep = np.zeros([10000],)\n",
    "    for i in range(10000):\n",
    "        local.append(a[i])\n",
    "        local.append(b[i])\n",
    "        #local.append(c[i])\n",
    "        local.append(d[i])\n",
    "        counts = np.bincount(local)\n",
    "        temp = np.argmax(counts)\n",
    "        new_list.append(temp)\n",
    "    #print(new_list)\n",
    "    return new_list\n",
    "    \n",
    "def maj_vote2(a,b,d):\n",
    "    local = []\n",
    "    new_list = []\n",
    "    #maj_rep = np.zeros([10000],)\n",
    "    for i in range(19999):\n",
    "        local.append(a[i])\n",
    "        local.append(b[i])\n",
    "        #local.append(c[i])\n",
    "        local.append(d[i])\n",
    "        counts = np.bincount(local)\n",
    "        temp = np.argmax(counts)\n",
    "        new_list.append(temp)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = np.zeros([10000],)\n",
    "new_list2 = np.zeros([19999],)\n",
    "new_list = maj_vote(y_pred_dense,y_pred_con,y_pred_logistic)\n",
    "new_list2 = maj_vote2(y_pred_dense2,y_pred_con2,y_pred_logistic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " USPS - confusion matrix using majority vote :\n",
      "[[   1    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [1999 2000 1999 2000 2000 2000 2000 2000 2000 2000]]\n",
      " \n",
      "0.10005500275013751\n"
     ]
    }
   ],
   "source": [
    "out_usps = confusion_matrix(new_list2, USPS_Target)\n",
    "print(\" USPS - confusion matrix using majority vote :\")\n",
    "print(out_usps)\n",
    "acc_usps = accuracy_score(new_list2, USPS_Target)\n",
    "print(\" \")\n",
    "print(acc_usps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " USPS - confusion matrix using majority vote :\n",
      "[[   1    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [1999 2000 1999 2000 2000 2000 2000 2000 2000 2000]]\n",
      " \n",
      "0.1011\n"
     ]
    }
   ],
   "source": [
    "out_mnist = confusion_matrix(new_list, test_target)\n",
    "print(\" USPS - confusion matrix using majority vote :\")\n",
    "print(out_usps)\n",
    "acc_mnist = accuracy_score(new_list, test_target)\n",
    "print(\" \")\n",
    "print(acc_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
